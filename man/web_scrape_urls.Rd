% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/web_scrape_urls.R
\name{web_scrape_urls}
\alias{web_scrape_urls}
\title{Scrape News Data from Various Sources}
\usage{
web_scrape_urls(x, cores = 3)
}
\arguments{
\item{x}{A character vector of URLs.}

\item{cores}{The number of cores to use for parallel processing.}
}
\value{
A data frame containing scraped news data.
}
\description{
Function accepts three types of input:
a Google News search query, a direct list of news URLs, or an RSS feed URL. Depending on the input type,
it either performs a Google News search and processes the resulting RSS feeds, directly scrapes the
provided URLs, or processes an RSS feed to extract URLs for scraping.
}
\examples{
\dontrun{
url <- 'https://www.nytimes.com/2024/03/25/nyregion/trump-bond-reduced.html'
article_tif <- web_scrape_urls(x = url, input = 'urls', cores = 1)
}


}
