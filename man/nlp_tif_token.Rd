% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nlp_tif_token.R
\name{nlp_tif_token}
\alias{nlp_tif_token}
\title{Tokenize Text Data (mostly) Non-Destructively}
\usage{
nlp_tif_token(tif, by = "text_id")
}
\arguments{
\item{tif}{A data frame containing the text to be tokenized and a document identifier in 'doc_id'.}

\item{by}{A character string specifying grouping column.}
}
\value{
A named list of tokens, where each list item corresponds to a document.
}
\description{
This function tokenizes text data from a data frame using the 'tokenizers' package, preserving the original text structure like capitalization and punctuation.
}
\examples{
# Assuming tif is a data frame with columns 'doc_id' and 'text'
# tif <- data.frame(doc_id = 1:2, text = c("Sample text 1", "Sample text 2"))
# tokens <- nlp_tif_token(tif)
}
