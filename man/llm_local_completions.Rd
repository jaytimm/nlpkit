% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_local_completions.R
\name{llm_local_completions}
\alias{llm_local_completions}
\title{LLM Local Completions}
\usage{
llm_local_completions(
  id,
  user_message = "",
  annotators = 1,
  model_name,
  temperature = 1,
  max_length = 1024,
  max_new_tokens = NULL,
  is_json_output = TRUE,
  max_attempts = 10
)
}
\arguments{
\item{id}{A unique identifier for the request.}

\item{user_message}{The message provided by the user.}

\item{annotators}{The number of annotators (default is 1).}

\item{model_name}{The name of the local model to use.}

\item{temperature}{The temperature for the model's output (default is 1).}

\item{max_length}{The maximum length of the input prompt (default is 1024).}

\item{max_new_tokens}{The maximum number of new tokens to generate (default is NULL).}

\item{is_json_output}{A logical indicating whether the output should be JSON (default is TRUE).}

\item{max_attempts}{The maximum number of attempts to make for generating valid output (default is 10).}
}
\value{
A data.table containing the generated text and metadata.
}
\description{
This function generates text using a local model.
}
\examples{
\dontrun{
llm_local_completions(id = "example_id", user_message = "What is the capital of France?", model_name = "mistralai/Mistral-7B-Instruct-v0.2")
}
}
