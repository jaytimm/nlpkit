---
output:
  md_document:
    variant: markdown_github
---

```{r include=FALSE}
Sys.setenv(OPENAI_API_KEY = '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')
```


# textpress

> A lightweight, versatile NLP companion in R.  The package integrates easily with common R tools and provides basic features for text processing and corpus search, as well as functionality for building text embeddings via OpenAI. Ideal for users who need a basic, unobtrusive NLP tool in R.

> nlp_get_gnews(), nlp_get_googlenews() -- A simple, lightweight news article extractor

License


## Installation

```{r eval=FALSE}
devtools::install_github("jaytimm/nlpx")
```


## Usage

## Some data

```{r message=FALSE, warning=FALSE}
library(dplyr)
articles <- quicknews::quicknews('ChatGPT',  cores = 5) |>
  filter(!is.na(text)) |>
  slice(5:30)
```


## Text processing

### Split sentences

```{r message=FALSE, warning=FALSE}
df_ss <- articles |>
  mutate(doc_id = row_number()) |>
  nlpx::nlp_split_sentences() 

df_ss |> slice(1:5) |> knitr::kable()
```



### Tokenization

```{r message=TRUE, warning=FALSE}
tokens <- df_ss |> nlpx::nlp_tokenize_text()
```

```{r echo=FALSE}
tokens[1]
```


### Cast tokens to df

```{r}
df <- tokens |> nlpx::nlp_cast_tokens()
df |> head() |> knitr::kable()
```





## Search text

```{r message=FALSE, warning=FALSE}
df_ss |>
  nlpx::nlp_search_corpus(search = 'artificial intelligence', 
                          highlight = c('**', '**'),
                          n = 0, 
                          is_inline = F) |>
  
  select(doc_id:text) |>
  slice(1:5) |>
  knitr::kable(escape = F)
```



## Search inline

```{r include=FALSE}
model = udpipe::udpipe_load_model('/home/jtimm/pCloudDrive/nlp/udpipe-model/english-ewt-ud-2.5-191206.udpipe')
```


### Annotate corpus with `udpipe`

```{r}
ud_annotated_corpus <- udpipe::udpipe(object = model,
                                      x = tokens,
                                      tagger = 'default',
                                      parser = 'none')
```


```{r echo=FALSE}
ud_annotated_corpus |> select(doc_id, start:xpos) |> slice(1:5) |> knitr::kable()
```


### Build inline text

```{r message=FALSE, warning=FALSE}
inline_ss <- ud_annotated_corpus |>
  mutate(inline = paste0(token, '/', xpos, '/', token_id)) |>
  tidyr::separate(col = doc_id, into = c('doc_id', 'sentence_id'), sep = '\\.') |>
  group_by(doc_id, sentence_id) |>
  summarise(text = paste0(inline, collapse = " "))

inline_ss$text[1] #|> strwrap(width = 40)
```


### Search for lexico-grammatical pattern

```{r}
inline_ss |>
  nlpx::nlp_search_corpus(search = 'JJ model', 
                          highlight = c('**', '**'),
                          n = 0,
                          is_inline = T) |>
  
  select(doc_id:text) |>
  slice(1:5) |>
  knitr::kable(escape = F)
```



## Search df

```{r message=FALSE, warning=FALSE}
df |>
  nlpx::nlp_search_df(search_col = 'token', 
                      id_col = 'text_id',
                      include = c('ChatGPT', 'prompt'),
                      logic = 'and',
                      exclude = NULL) |>
  
  group_by(text_id) |>
  summarize(text = paste0(token, collapse = ' ')) |>
  slice(1:5) |>
  knitr::kable()
```


## OpenAI embeddings

```{r}
vstore <- df_ss |>
  mutate(words = tokenizers::count_words(text)) |>
  filter(words > 20, words < 60) |>
  mutate(batch_id = nlpx::nlp_batch_cumsum(x = words,
                                           threshold = 10000)) |>
  
  nlpx::nlp_fetch_openai_embs(text_id = 'text_id',
                              text = 'text',
                              batch_id = 'batch_id')
```



## Semantic neighbors

### Sentence-level

```{r}
q <- 'What are some concerns about the impact of
advanced AI models like ChatGPT?'
```



```{r}
query <- nlpx::nlp_fetch_openai_embs(query = q)

nlpx::nlp_find_neighbors(x = query, 
                         matrix = vstore, 
                         n = 5) |>
  
  left_join(df_ss, by = c('term2' = 'text_id')) |>
  select(cos_sim:text) |>
  knitr::kable()
```


### Word-level

```{r message=FALSE, warning=FALSE}
mesht <- pubmedtk::data_mesh_thesuarus()
embs <- pubmedtk::data_mesh_embeddings()

nlpx::nlp_find_neighbors(x = 'Artificial Intelligence',
                         matrix = embs,
                         n = 10) |>
  knitr::kable()
```


## Summary

