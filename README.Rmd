---
output:
  md_document:
    variant: markdown_github
always_allow_html: true
---

`r badger::badge_github_actions("jaytimm/textpress")`

```{r include=FALSE}
Sys.setenv(OPENAI_API_KEY = "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")
# A combo of text2df, quicknews, chittr, and textsearch
```


# textpress

A lightweight, versatile NLP companion in R.  A small menu approach. No substantial dependencies. Data-frame-centric.  Transparent & step wise. Easy integration into LLM-based RAG systems.  The package provides features for (1) basic text processing, (2) corpus search, and (3) web scraping.  Additionally included are utility functions for (4) building text embeddings via the HuggingFace API, and (5) fetching chat completions via the OpenAI API.  Ideal for users who need a basic, unobtrusive NLP tool in R.  

`textpress` does not provide any language models, part-of-speech tagging, topic models, etc., but it can be used in conjunction with other packages that provide these features.  At some point, Python becomes ... 





## Installation

```{r eval=FALSE}
devtools::install_github("jaytimm/textpress")
```


## Usage

## Web scraping

### Articles & metadata from GoogleNews

```{r}
library(dplyr)
meta <- textpress::web_process_gnewsfeed(x = 'Wildlife Conservation Efforts')
meta |> select(date, source, title, url) |> head() |> knitr::kable()
```




### Scrape URLs

> Preserves article structure via html nodes.  Insomuchas distinct html nodes are used for delineating paragraphs, eg, as opposed to creating space for online ads, etc.  Two newlines ('\n\n') are used when concatenating individual nodes as full text.

```{r message=FALSE, warning=FALSE}
articles <- textpress::web_scrape_urls(
  x = meta$url,
  input = "urls",
  cores = 8
  )

pretty_prompt <- function(x, width = 50L, char_length = NULL) {
  # Truncate the text to the character limit if specified
  if (!is.null(char_length) && nchar(x) > char_length) {
    x <- substr(x, 1, char_length)
  }
  
  # Wrap the text and write lines
  wrapped_text <- strwrap(x, width = width)
  writeLines(wrapped_text)
}

articles$text[1] |> pretty_prompt(char_length = 900)
```



### One fell swoop

> Alternatively:

```{r eval=FALSE}
articles <- textpress::web_scrape_urls(
  x = "Wildlife Conservation Efforts",
  input = "search",
  cores = 6
  )
```



## Text processing

### Split paragraphs

```{r message=FALSE, warning=FALSE}
tif_paragraphs <- articles1 |>
  textpress::nlp_split_paragraphs(paragraph_delim = "\\n+")
##  "\t " -- as empty paragraphs remain -- 
```



### Split sentences

> A super-simple sentence tokenizer.  The most commomn abbreviations are ignored when tokenizing.  This list is small, but accounts for most problematic abbreviations.  

```{r}
textpress::abbreviations
```


```{r}
tif_sentences <- tif_paragraphs |>
  textpress::nlp_split_sentences(text_hierarchy = c('doc_id', 'paragraph_id'))
```




### Tokenization

```{r message=TRUE, warning=FALSE}
tokens <- tif_sentences |> textpress::nlp_tokenize_text()
```

```{r echo=FALSE}
tokens[1]
```


### Cast tokens to a data frame

```{r}
dtm <- tokens |> 
  textpress::nlp_cast_tokens() |>
  
  tidyr::separate(col = 'id', 
                  into = c('doc_id', 'paragraph_id', 'sentence_id'), 
                  sep = '\\.')

dtm |> slice(1:10) |> knitr::kable()
```




## Search text

>> THIS IS THROWING ERRORs now -- when cores > 1 -- 

```{r message=FALSE, warning=FALSE}
search_results <- tif_sentences |>
  textpress::sem_search_corpus(
    search = "climate change",
    highlight = c("<b>", "</b>"),
    context_size = 0,
    cores = 1,
    is_inline = F
  )

search_results |>
  select(doc_id:text) |>
  sample_n(10) |>
  arrange(doc_id) |>
  knitr::kable(escape = F)
```




## Search df

> This still has value -- needs to be reframed -- 


> Identify sentences that contain both `ChatGPT` and `education`. OR paragrahs -- or whatever -- 

```{r message=FALSE, warning=FALSE}
tokens |>
  textpress::nlp_cast_tokens() |>
  
  textpress::search_df(
    search_col = "token",
    id_col = "text_id",
    include = c("ChatGPT", "education"),
    logic = "and",
    exclude = NULL
  ) |>
  group_by(text_id) |>
  summarize(text = paste0(token, collapse = " ")) |>
  slice(1:5) |>
  knitr::kable()
```



## Retrieval-augmented generation

### Sentence Window Retrieval

> Chunks built out of (n = `chunk_size`) sentences; context added as (n = `context_size`) sentences as window before and after chunk.  Chunks (in bold-face below) are indexed in vector store for retrieval; chunks plus contexts (normal font below) serve as input to LLM.

```{r}
## chunk_id output is presently concatenated -- 

tif_chunks <- tif_sentences |>
  textpress::nlp_build_chunks(
    text_hierarchy = c('doc_id', 'paragraph_id', 'sentence_id'),
    chunk_size = 2,
    context_size = 1
  )

set.seed(99)
tif_chunks |>
  sample_n(3) |>
  select(-chunk) |>
  knitr::kable(escape = F)
```




### HuggingFace embeddings

> API call -- for lightweight embedding building.  DEmo, etc.  Easy enough to --- 

```{r}
api_token <- "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"
```


```{r}
api_url <- "https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2"

vstore <- tif_chunks  |>
  textpress::api_huggingface_embeddings(#text_hierarchy = c('doc_id', 'paragraph_id', 'sentence_id'),
                                        text_hierarchy = c('chunk_id'),
                                        api_token = api_token,
                                        api_url = api_url)

## Error in dimnames(x) <- dn :   length of 'dimnames' [1] not equal to array extent
```




### Semantic search

```{r}
q <- "What are some concerns about the impact of
      advanced AI models like ChatGPT?"
```



```{r}
query <- textpress::rag_fetch_openai_embs(query = q)

textpress::search_semantics(
  x = query,
  matrix = vstore,
  n = 5
) |>
  left_join(chunks, by = c("term2" = "chunk_id")) |>
  select(cos_sim:chunk) |>
  knitr::kable()
```




```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
### Word-level

# mesht <- pubmedtk::data_mesh_thesuarus()
# embs <- pubmedtk::data_mesh_embeddings()
#
# textpress::nlp_find_neighbors(x = 'Artificial Intelligence',
#                          matrix = embs,
#                          n = 10) |>
#   knitr::kable()
```


## Summary

