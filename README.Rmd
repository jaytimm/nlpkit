---
output:
  md_document:
    variant: markdown_github
---

# nlpx

A lightweight, versatile NLP companion in R.

```{r eval=FALSE}
devtools::install_github("jaytimm/nlpx")
```


## Some data

```{r message=FALSE, warning=FALSE}
library(dplyr)
mm <- quicknews::qnews_build_rss(x = 'ChatGPT') |>
  quicknews::qnews_parse_rss() |>
  mutate(url = quicknews::qnews_get_rurls(link))

articles <- quicknews::qnews_extract_article(
  x = mm$url[1:25], cores = 3) |>
  left_join(mm)
```



## Core NLP tasks

### Simple annotation

```{r message=FALSE, warning=FALSE}
df_ss <- articles |>
  mutate(doc_id = row_number()) |>
  nlpx::nlp_split_sentences() 

df_ss |> head() |> knitr::kable()
```


```{r message=TRUE, warning=FALSE}
df <- df_ss |>
  nlpx::nlp_tokenize_text() |>
  nlpx::nlp_cast_tokens()

df |> head()
```


## Search

### Text

```{r message=FALSE, warning=FALSE}
df_ss |>
  nlpx::nlp_search_corpus(search = 'artificial intelligence', 
                          highlight = c('**', '**'),
                          n = 0) |>
  
  select(doc_id:text) |>
  knitr::kable(escape = F)
```


### df

```{r message=FALSE, warning=FALSE}
df |>
  nlpx::nlp_search_df(search_col = 'token', 
                      id_col = 'text_id',
                      include = c('ChatGPT', 'prompt'),
                      logic = 'and',
                      exclude = NULL) |>
  
  group_by(text_id) |>
  summarize(text = paste0(token, collapse = ' ')) |>
  knitr::kable()
```



